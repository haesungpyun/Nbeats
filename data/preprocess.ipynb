{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c23a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "868af49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d64cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv('./data/calendar.csv')\n",
    "train_val = pd.read_csv('./data/sales_train_validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3971c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_val = calendar.copy()\n",
    "\n",
    "for i in range(1914, 1969):\n",
    "    cal_val.drop(index=i, axis=0, inplace = True)\n",
    "cal_val = cal_val[['date', 'weekday', 'd']]\n",
    "cal_val['d'] = cal_val['d'].str.split('_').str[1]\n",
    "cal_val\n",
    "\n",
    "train_val['id'] = train_val['store_id'] + str('_') + train_val['dept_id']\n",
    "train_val = train_val.drop(columns = ['store_id', 'dept_id', 'item_id', 'cat_id', 'state_id'], axis=1)\n",
    "\n",
    "for col in train_val.columns[1:]:\n",
    "    train_val.rename(columns = {col: col.split('_')[-1]}, inplace=True)\n",
    "\n",
    "train_group = train_val.groupby('id')\n",
    "train_group = train_group.sum()\n",
    "train_group.reset_index(inplace=True)\n",
    "train_group\n",
    "\n",
    "train_melt = pd.melt(train_group, id_vars = 'id', \n",
    "                  value_vars = [col for col in train_group.columns if not col.startswith('i')],\n",
    "                  var_name = 'd', value_name = 'sales')\n",
    "\n",
    "train_melt = train_melt.merge(cal_val, on ='d', copy=False)\n",
    "\n",
    "train_melt['d'] = train_melt['d'].astype('int64')\n",
    "train_melt['date'] = pd.to_datetime(train_melt['date'])\n",
    "train_melt = train_melt.sort_values(by=['id', 'd'], ascending=True)\n",
    "\n",
    "train_melt.reset_index(inplace=True)\n",
    "train_melt.drop(columns='index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d05080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1_FOODS_1</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1_FOODS_1</td>\n",
       "      <td>2</td>\n",
       "      <td>284</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1_FOODS_1</td>\n",
       "      <td>3</td>\n",
       "      <td>214</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1_FOODS_1</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_1_FOODS_1</td>\n",
       "      <td>5</td>\n",
       "      <td>182</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133905</th>\n",
       "      <td>WI_3_HOUSEHOLD_2</td>\n",
       "      <td>1909</td>\n",
       "      <td>148</td>\n",
       "      <td>2016-04-20</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133906</th>\n",
       "      <td>WI_3_HOUSEHOLD_2</td>\n",
       "      <td>1910</td>\n",
       "      <td>142</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133907</th>\n",
       "      <td>WI_3_HOUSEHOLD_2</td>\n",
       "      <td>1911</td>\n",
       "      <td>166</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133908</th>\n",
       "      <td>WI_3_HOUSEHOLD_2</td>\n",
       "      <td>1912</td>\n",
       "      <td>232</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133909</th>\n",
       "      <td>WI_3_HOUSEHOLD_2</td>\n",
       "      <td>1913</td>\n",
       "      <td>201</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133910 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     d  sales       date    weekday\n",
       "0           CA_1_FOODS_1     1    297 2011-01-29   Saturday\n",
       "1           CA_1_FOODS_1     2    284 2011-01-30     Sunday\n",
       "2           CA_1_FOODS_1     3    214 2011-01-31     Monday\n",
       "3           CA_1_FOODS_1     4    175 2011-02-01    Tuesday\n",
       "4           CA_1_FOODS_1     5    182 2011-02-02  Wednesday\n",
       "...                  ...   ...    ...        ...        ...\n",
       "133905  WI_3_HOUSEHOLD_2  1909    148 2016-04-20  Wednesday\n",
       "133906  WI_3_HOUSEHOLD_2  1910    142 2016-04-21   Thursday\n",
       "133907  WI_3_HOUSEHOLD_2  1911    166 2016-04-22     Friday\n",
       "133908  WI_3_HOUSEHOLD_2  1912    232 2016-04-23   Saturday\n",
       "133909  WI_3_HOUSEHOLD_2  1913    201 2016-04-24     Sunday\n",
       "\n",
       "[133910 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "901dd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_melt.to_pickle(\"./data/m5_preprocessed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "497e97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/m5_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e582d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, num_samples, ):\n",
    "    data_dict = {}\n",
    "    data_len = 30\n",
    "    jump = 1\n",
    "    input_size = 1\n",
    "    output_size = 1\n",
    "    \n",
    "    id_col='id'\n",
    "    input_cols = 'sales'\n",
    "    target_col = 'sales'\n",
    "    time_col = 'd'\n",
    "    \n",
    "    sampling_end_locations = []\n",
    "    split_data_map = {}\n",
    "    \n",
    "    for id_name, df in data.groupby(id_col):\n",
    "        num_entries = len(df)\n",
    "        sampling_end_locations += [\n",
    "            (id_name, data_len + i)\n",
    "            for i in range(num_entries - data_len  + 1)\n",
    "            if (i % jump) == 0\n",
    "        ]\n",
    "        \n",
    "        split_data_map[id_name] = df\n",
    "        \n",
    "    if num_samples == 'max':\n",
    "        samples = len(sampling_end_locations)\n",
    "\n",
    "    else: \n",
    "        samples = num_samples\n",
    "\n",
    "    inputs = np.zeros((samples, data_len, input_size))\n",
    "    outputs = np.zeros((samples, data_len, output_size))\n",
    "    time = np.empty((samples, data_len, 1), dtype=object)\n",
    "    identifiers = np.empty((samples, data_len+ , 1), dtype=object)\n",
    "\n",
    "    if (samples > 0) & (len(sampling_end_locations) >= samples):\n",
    "        print('Extracting {} smaples...'.format(samples))\n",
    "\n",
    "        ranges = [\n",
    "            sampling_end_locations[i] for i in np.random.choice(\n",
    "                len(sampling_end_locations), samples, replace = True)\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Smaple is over')\n",
    "\n",
    "    for i, tup in enumerate(ranges):\n",
    "        if((i+1)% 1000) == 0:\n",
    "            print(i+1, 'of', smaples, 'smaples done...')\n",
    "\n",
    "        id_name, end_idx = tup\n",
    "        sliced = split_data_map[id_name].iloc[end_idx-data_len : end_idx]\n",
    "\n",
    "        outputs[i, :, :] = sliced[[target_col]]\n",
    "        inputs[i, :, :] = sliced[[input_cols]]\n",
    "        time[i, :, 0] = sliced[time_col]\n",
    "        identifiers[i, :, 0] = sliced[id_col]\n",
    "\n",
    "    data_dict['inputs'] = inputs\n",
    "    data_dict['targets'] = outputs\n",
    "    data_dict['time'] = time\n",
    "    data_dict['identifier'] = identifiers\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26b5b06a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 100 smaples...\n"
     ]
    }
   ],
   "source": [
    "data_dict= preprocess(df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac5fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
